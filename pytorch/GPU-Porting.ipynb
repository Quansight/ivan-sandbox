{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Porting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually check:\n",
    "\n",
    "* `AT_CHECK` just have 2 args: condition and message\n",
    "* Check order of height, width in parameters of functions such as: resize,  \n",
    "\n",
    "## Warnings:\n",
    "\n",
    "* not garanteed for nested parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = os.environ['HOME']\n",
    "output_path = '/tmp/pytorch/output/gpu/'\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "pytorch_path = os.path.join(\n",
    "    home_path,\n",
    "    'dev/quansight/pytorch-project/pytorch'\n",
    ")\n",
    "thcunn_path = os.path.join(pytorch_path, 'aten/src/THCUNN')\n",
    "at_cuda_path = os.path.join(pytorch_path, 'aten/src/ATen/native/cuda')\n",
    "\n",
    "thcunn_files = [\n",
    "    'Col2Im.cu',\n",
    "]\n",
    "thcunn_h_files = ['im2col.h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {pytorch_path}/.clang-format {output_path} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove `aten/src/THNN/generic/*.c` files that is being ported\n",
    "# Remove functions to be ported from:\n",
    "# `/aten/src/THCUNN/CMakeLists.txt`\n",
    "# `/aten/src/THCUNN/generic/THCUNN.h`\n",
    "# `/aten/src/THNN/init.cpp`\n",
    "# `/aten/src/ATen/nn.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Col2Im.cu']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _remove_ext(v):\n",
    "    if '.' in v:\n",
    "        return v.split('.')[0]\n",
    "    return v\n",
    "\n",
    "def _get_ext(v):\n",
    "    if '.' in v:\n",
    "        return '.' + v.split('.')[-1]\n",
    "    return ''\n",
    "    \n",
    "RULES_NAME = [\n",
    "    lambda v, w='Temporal': (\n",
    "        _remove_ext(v).replace(w, '') + '1d' + _get_ext(v)\n",
    "        if v.startswith(w)\n",
    "        else v\n",
    "    ),\n",
    "    lambda v, w='Spatial': (\n",
    "        _remove_ext(v).replace(w, '') + '2d' + _get_ext(v)\n",
    "        if v.startswith(w)\n",
    "        else v\n",
    "    ),\n",
    "    lambda v, w='Volumetric': (\n",
    "        _remove_ext(v).replace(w, '') + '3d' + _get_ext(v)\n",
    "        if v.startswith(w)\n",
    "        else v\n",
    "    ),\n",
    "]\n",
    "\n",
    "RULES_NAME_EXTRA = RULES_NAME + []\n",
    "\n",
    "RULES = [] + RULES_NAME_EXTRA\n",
    "\n",
    "\n",
    "def apply_rules(rules, text):\n",
    "    _fn = text\n",
    "    for r in rules:\n",
    "        _fn = r(_fn)\n",
    "    return _fn\n",
    "\n",
    "\n",
    "def convert_filenames(filenames, extra_rules: list = []):\n",
    "    rules = RULES + extra_rules\n",
    "    \n",
    "    result = []\n",
    "    for fn in filenames:\n",
    "        result.append(apply_rules(rules, fn))\n",
    "    return result\n",
    "\n",
    "\n",
    "# test\n",
    "at_cuda_files = convert_filenames(thcunn_files)\n",
    "at_cuda_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aten_cuda_files(\n",
    "    output_path: str,\n",
    "    thcunn_path: str,\n",
    "    at_cuda_path: str,\n",
    "    th_at_filenames: list,\n",
    "    just_gpu_porting: bool = True\n",
    "): \n",
    "    \"\"\"Porting code from `/aten/src/THCUNN/generic` and `/aten/src/THCUNN`\n",
    "    to `/aten/src/ATen/native/cuda/`\n",
    "    \n",
    "    \"\"\"\n",
    "    for th_fn, at_fn in th_at_filenames:\n",
    "        # get file data from THCUNN\n",
    "        path_src = os.path.join(thcunn_path, th_fn)\n",
    "        at_file_output_path = os.path.join(output_path, at_fn)\n",
    "        # copy also properties and metadata\n",
    "        shutil.copy2(path_src, at_file_output_path)\n",
    "        # write output file\n",
    "        with open(at_file_output_path, 'a') as f_dst:\n",
    "            # get file data from THCUNN/generic\n",
    "            f_dst.write('\\n')\n",
    "            path_src = os.path.join(thcunn_path, 'generic', th_fn) \n",
    "            if not os.path.isfile(path_src):\n",
    "                continue\n",
    "            with open(path_src, 'r') as f_src:\n",
    "                f_dst.write('\\n// THCUNN/generic\\n')\n",
    "                f_dst.write(f_src.read())\n",
    "            \n",
    "            # get file data from ATen/native/cuda\n",
    "            # expetec a initial gpu porting after a `just cpu porting`\n",
    "            if just_gpu_porting:\n",
    "                f_dst.write('\\n')\n",
    "                path_src = os.path.join(at_cuda_path, at_fn)\n",
    "                if os.path.isfile(path_src):\n",
    "                    with open(path_src, 'r') as f_src:\n",
    "                        f_dst.write('\\n// ATen/native/cuda\\n')\n",
    "                        f_dst.write(f_src.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/pytorch/output/gpu/\n",
      "total 48K\n",
      "drwxrwxr-x 2 xmn xmn 4,0K may 17 16:14 .\n",
      "drwxrwxr-x 4 xmn xmn 4,0K may 15 22:32 ..\n",
      "-rw-rw-r-- 1 xmn xmn 2,6K may 16 01:02 .clang-format\n",
      "-rw-rw-r-- 1 xmn xmn 5,3K may 17 16:14 Col2Im.cu\n",
      "-rw-rw-r-- 1 xmn xmn  11K may 16 01:02 Im2Col.cu\n",
      "-rw-rw-r-- 1 xmn xmn 5,9K may 16 01:02 im2col.cuh\n",
      "-rw-rw-r-- 1 xmn xmn 5,8K may 16 00:52 im2col.h\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "create_aten_cuda_files(\n",
    "    output_path, \n",
    "    thcunn_path,\n",
    "    at_cuda_path,\n",
    "    zip(thcunn_files, at_cuda_files)\n",
    ")\n",
    "\n",
    "print(output_path)\n",
    "!ls -lah {output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_replace_rule(by, to):\n",
    "    return lambda v: v.replace(by, to)\n",
    "\n",
    "\n",
    "def th2at(text: str, extra_rules: list = []):\n",
    "    # replace rules\n",
    "    rules = [\n",
    "        ('#include <THCUNN/THCUNN.h>', \n",
    "         '/* TODO: remove duplicated includes */\\n'\n",
    "         '#include <ATen/ATen.h>\\n'\n",
    "         '#include <ATen/AccumulateType.h>\\n'\n",
    "         '#include <ATen/NativeFunctions.h>\\n'\n",
    "         '#include <ATen/TensorUtils.h>\\n'\n",
    "         '#include <ATen/Utils.h>\\n'\n",
    "         '#include <ATen/cuda/CUDAContext.h>\\n'\n",
    "         '#include <ATen/cuda/CUDAApplyUtils.cuh>\\n'\n",
    "        ),\n",
    "        ('getSize(', 'size('),\n",
    "        ('Acctype', 'accscalar_t'),\n",
    "        ('Dtype', 'scalar_t'),\n",
    "        ('ScalarConvert<scalar_t, accscalar_t>::to',\n",
    "         'static_cast<accscalar_t>'),\n",
    "        ('ScalarConvert<accscalar_t, scalar_t>::to',\n",
    "         'static_cast<scalar_t>'),\n",
    "        ('THCNumerics<scalar_t>::min()',\n",
    "         'at::numeric_lmits<scalar_t>::lowest()'),\n",
    "        ('THCUNN_argCheck', '/* TODO: AT_CHECK just have 2 args */\\n   AT_CHECK'),\n",
    "        ('THAssert', 'AT_ASSERT'),\n",
    "        ('THCTensor ', 'Tensor '),\n",
    "        ('THCTensor*', 'Tensor*'),\n",
    "        ('putDepth', 'put_depth'),\n",
    "        ('putHeight', 'put_height'),\n",
    "        ('putWidth', 'put_width'),\n",
    "        ('putPlane', 'put_plane'),\n",
    "        ('putLength', 'put_length'),\n",
    "        ('gradOut', 'grad_out'),\n",
    "        ('gradIn', 'grad_in'),\n",
    "        ('nBatch', 'nbatch'),\n",
    "        ('nChannel', 'nchannel'),\n",
    "        ('THCState *state,', ''),\n",
    "        ('THCState* state,', ''),\n",
    "        ('THCDeviceTensor', 'PackedTensorAccessor'),\n",
    "        ('state, ', ''),\n",
    "        ('THCState_getCurrentStream(state)', 'at::cuda::getCurrentCUDAStream()'),\n",
    "        ('THArgCheck(', '/* TODO: AT_CHECK just have 2 args */\\n   AT_CHECK('),\n",
    "        ('THCudaCheck(cudaGetLastError())',\n",
    "         'AT_CUDA_CHECK(cudaGetLastError())'),\n",
    "        ('NULL,', 'Tensor(),'),\n",
    "        ('THCNumerics<scalar_t>::min()', 'at::numeric_limits<scalar_t>::lowest()'),\n",
    "        ('->dim()', '.dim()'),\n",
    "        ('->size(', '.size('),\n",
    "        ('THCeilDiv', 'cuda::ATenCeilDiv'),\n",
    "        ('nInput', 'n_input'),\n",
    "        ('nOutput', 'n_output'),\n",
    "        ('THCTensor_(new)(state)', 'Tensor()'),\n",
    "        ('batchSize', 'batch_size'),\n",
    "        ('THError', 'AT_ERROR'),\n",
    "        ('THCTensor_(free)', '// TODO: remove it: THCTensor_(free)'),\n",
    "        ('#if', '// #if'),\n",
    "        ('#def', '// #def'),\n",
    "        ('#else', '// #else'),\n",
    "        ('#endif', '// #endif'),\n",
    "        ('updateOutput', 'out_cuda'),\n",
    "        ('updateGradInput', 'backward_out_cuda')\n",
    "    ] + extra_rules\n",
    "    \n",
    "    for by, to in rules:\n",
    "        text = text.replace(by, to)\n",
    "        \n",
    "    # regex rules\n",
    "    # TODO:\n",
    "    # - toDeviceTensor\n",
    "    rules = (\n",
    "        # rule, output pattern \n",
    "        (r'THNN_\\((.*)\\)', None),\n",
    "        (r'THCTensor_\\(size\\)\\(\\s*([^,]*),\\s*(.*)\\s*\\)', '{}.size({})'),\n",
    "        (r'THCTensor_\\(resize([0-9]*)d\\)\\(\\s*([^,]*),\\s*(.*)\\s*\\)', '{1}.resize_({{ {2} }})'),\n",
    "        (r'THCTensor_\\(nDimensionLegacyNoScalars\\)\\(\\s*(.*)\\s*\\)', '{}.ndimension()'),\n",
    "        (r'THCTensor_\\(zero\\)\\(\\s*(.*)\\s*\\)', '{0}.zero_()'),\n",
    "        (r'THCTensor_\\(select\\)\\(\\s*([^,]*),\\s*(.*)\\s*\\)', '{0}.select({1})'),\n",
    "        (r'THCTensor_\\(data\\)\\(\\s*(.*)\\s*\\)', '{0}.data()'),\n",
    "        (r'[!](.*)->is_empty\\(\\)', '{}.numel() != 0'),\n",
    "        (r'(\\w)\\s*!=\\s*NULL', '{}.defined()'),\n",
    "        (r'THCUNN_assertSameGPU\\([0-9]*,\\s*(.*)\\s*\\);', \n",
    "         '/* TODO: TensorArg tensorname_arg{{tensorname, \"tensorname\", 1}}; */\\n'\n",
    "         '/* TODO: checkAllSameGPU should use TensorArg */\\n'\n",
    "         'checkAllSameGPU(\\n'\n",
    "         '  \"/* TODO: use the name of the function as description here */\",'\n",
    "         '  {{ {} }});'), \n",
    "        (r'(.*)=\\s*THCTensor_\\(newContiguous\\)\\(\\s*(.*)\\s*\\);', \n",
    "         'Tensor {0} = {1}_.contiguous(); /* TODO: add _ to the arg definition above */'),\n",
    "        (r'accscalar_t\\(\\s*(.*)\\s*\\)', 'static_cast<accscalar_t>({})'),\n",
    "        (r'THCNumerics\\<scalar_t\\>::ne\\(\\s*(.*),\\s*(.*)\\s*\\)\\s*', '{} != {}'),\n",
    "    )\n",
    "    \n",
    "    for rule, output_format in rules:\n",
    "        result = re.finditer(rule, text, re.MULTILINE)\n",
    "        for r in result:\n",
    "            _in = r.group(0)\n",
    "            if output_format is None:\n",
    "                _out = r.group(1)\n",
    "            else:\n",
    "                _out = output_format.format(*r.groups())\n",
    "            text = text.replace(_in, apply_rules(RULES_NAME_EXTRA, _out))\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def cuda_th2at(files_path: list, extra_rules: list = []):\n",
    "    for f_path in files_path:\n",
    "        with open(f_path, 'r') as f:\n",
    "            f_content = th2at(f.read(), extra_rules)\n",
    "        \n",
    "        with open(f_path, 'w') as f:\n",
    "            f.write(f_content)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* TODO: remove duplicated includes */\n",
      "#include <ATen/ATen.h>\n",
      "#include <ATen/AccumulateType.h>\n",
      "#include <ATen/NativeFunctions.h>\n",
      "#include <ATen/TensorUtils.h>\n",
      "#include <ATen/Utils.h>\n",
      "#include <ATen/cuda/CUDAContext.h>\n",
      "#include <ATen/cuda/CUDAApplyUtils.cuh>\n",
      "\n",
      "#include <THC/THCStorage.hpp>\n",
      "#include <THC/THCTensor.hpp>\n",
      "#include <THCUNN/common.h>\n",
      "\n",
      "#include <TH/THHalf.h>\n",
      "#include <THCUNN/THCHalfAutoNumerics.cuh>\n",
      "\n",
      "#include <THC/THCGenerateFloatTypes.h>\n",
      "#include <THCUNN/generic/Col2Im.cu>\n",
      "\n",
      "#include <ATen/native/cuda/im2col.cuh>\n",
      "\n",
      "// THCUNN/generic\n",
      "// #ifndef THC_GENERIC_FILE\n",
      "// #define THC_GENERIC_FILE \"THCUNN/generic/Col2Im.cu\"\n",
      "// #else\n",
      "\n",
      "#include <ATen/div_rtn.h>\n",
      "\n",
      "static inline void Col2Im_shape_check(\n",
      "\n",
      "    Tensor* input,\n",
      "    Tensor* grad_output,\n",
      "    int64_t output_height,\n",
      "    int64_t output_width,\n",
      "    int64_t kernel_height,\n",
      "    int64_t kernel_width,\n",
      "    int64_t dilation_height,\n",
      "    int64_t dilation_width,\n",
      "    int64_t padilation_height,\n",
      "    int64_t padilation_width,\n",
      "    int64_t stride_height,\n",
      "    int64_t stride_width) {\n",
      "  /* TODO: AT_CHECK just have 2 args */\n",
      "  AT_CHECK(\n",
      "      kernel_width > 0 && kernel_height > 0,\n",
      "      6,\n",
      "      \"kernel size should be greater than zero, but got kernel_height: %d kernel_width: %d\",\n",
      "      kernel_height,\n",
      "      kernel_width);\n",
      "  /* TODO: AT_CHECK just have 2 args */\n",
      "  AT_CHECK(\n",
      "      stride_width > 0 && stride_height > 0,\n",
      "      12,\n",
      "      \"stride should be greater than zero, but got stride_height: %d stride_width: %d\",\n",
      "      stride_height,\n",
      "      stride_width);\n",
      "  /* TODO: AT_CHECK just have 2 args */\n",
      "  AT_CHECK(\n",
      "      dilation_width > 0 && dilation_height > 0,\n",
      "      8,\n",
      "      \"dilation should be greater than zero, but got dilation_height: %d dilation_width: %d\",\n",
      "      dilation_height,\n",
      "      dilation_width);\n",
      "\n",
      "  int64_t ndim = input.ndimension();\n",
      "  /* TODO: AT_CHECK just have 2 args */\n",
      "  AT_CHECK(\n",
      "      state,\n",
      "      input.numel() != 0 && (ndim == 2 || ndim == 3),\n",
      "      2,\n",
      "      input,\n",
      "      \"Expected non-empty 2D or 3D input tensor, but got input of shape %s\");\n",
      "\n",
      "  int batch_dim = (ndim == 3) ? 0 : -1;\n",
      "  int64_t n_input_plane = input.size(batch_dim + 1);\n",
      "\n",
      "  if (n_input_plane % (kernel_width * kernel_height) != 0) {\n",
      "    AT_ERROR(\n",
      "        \"Expected size of input's dimension 1 to be divisible by the \"\n",
      "        \"product of kernel_size, but got input.size(1)=%lld and \"\n",
      "        \"kernel_size=(%d, %d).\",\n",
      "        (long long)n_input_plane,\n",
      "        kernel_height,\n",
      "        kernel_width);\n",
      "  }\n",
      "\n",
      "  int64_t input_length = input.size(batch_dim + 2);\n",
      "  int64_t nBlockstride_height =\n",
      "      div_rtn<int64_t>(\n",
      "          output_height + 2 * padilation_height -\n",
      "              dilation_height * (kernel_height - 1) - 1,\n",
      "          stride_height) +\n",
      "      1;\n",
      "  int64_t nBlockstride_width = div_rtn<int64_t>(\n",
      "                                   output_width + 2 * padilation_width -\n",
      "                                       dilation_width * (kernel_width - 1) - 1,\n",
      "                                   stride_width) +\n",
      "      1;\n",
      "\n",
      "  if (input_length != (nBlockstride_height * nBlockstride_width)) {\n",
      "    AT_ERROR(\n",
      "        \"Given output_size=(%d, %d), kernel_size=(%d, %d), \"\n",
      "        \"dilation=(%d, %d), padding=(%d, %d), stride=(%d, %d), expected \"\n",
      "        \"size of input's dimension 2 to match the calculated number of \"\n",
      "        \"sliding blocks %lld * %lld = %lld, but got input.size(2)=%lld.\",\n",
      "        output_height,\n",
      "        output_width,\n",
      "        kernel_height,\n",
      "        kernel_width,\n",
      "        dilation_height,\n",
      "        dilation_width,\n",
      "        padilation_height,\n",
      "        padilation_width,\n",
      "        stride_height,\n",
      "        stride_width,\n",
      "        (long long)nBlockstride_height,\n",
      "        (long long)nBlockstride_width,\n",
      "        (long long)(nBlockstride_height * nBlockstride_width),\n",
      "        (long long)input_length);\n",
      "  }\n",
      "\n",
      "  if (output_width < 1 || output_height < 1) {\n",
      "    AT_ERROR(\n",
      "        \"Expected output spatial size to be positive, but got: output_size=(%d, %d).\",\n",
      "        output_height,\n",
      "        output_width);\n",
      "  }\n",
      "}\n",
      "\n",
      "void Col2Im_out_cuda(\n",
      "\n",
      "    Tensor* input,\n",
      "    Tensor* output,\n",
      "    int64_t output_height,\n",
      "    int64_t output_width,\n",
      "    int64_t kernel_height,\n",
      "    int64_t kernel_width,\n",
      "    int64_t dilation_height,\n",
      "    int64_t dilation_width,\n",
      "    int64_t padilation_height,\n",
      "    int64_t padilation_width,\n",
      "    int64_t stride_height,\n",
      "    int64_t stride_width) {\n",
      "  /* TODO: TensorArg tensorname_arg{tensorname, \"tensorname\", 1}; */\n",
      "  /* TODO: checkAllSameGPU should use TensorArg */\n",
      "  checkAllSameGPU(\n",
      "      \"/* TODO: use the name of the function as description here */\",\n",
      "      {input, output});\n",
      "\n",
      "  Col2Im_shape_check(\n",
      "      state,\n",
      "      input,\n",
      "      Tensor(),\n",
      "      output_height,\n",
      "      output_width,\n",
      "      kernel_height,\n",
      "      kernel_width,\n",
      "      dilation_height,\n",
      "      dilation_width,\n",
      "      padilation_height,\n",
      "      padilation_width,\n",
      "      stride_height,\n",
      "      stride_width);\n",
      "\n",
      "  bool batched_input = true;\n",
      "  if (input.dim() == 2) {\n",
      "    // Force batch\n",
      "    batched_input = false;\n",
      "    input.resize_({1, input.size(0), input.size(1)});\n",
      "  }\n",
      "\n",
      "  int64_t batch_size = input.size(0);\n",
      "  int64_t n_input_plane = input.size(1);\n",
      "  int64_t n_output_plane = n_input_plane / (kernel_width * kernel_height);\n",
      "\n",
      "  Tensor input =\n",
      "      input_.contiguous(); /* TODO: add _ to the arg definition above */\n",
      "\n",
      "  output.resize_({batch_size, n_output_plane, output_height, output_width});\n",
      "  output.zero_();\n",
      "\n",
      "  Tensor* input_n = Tensor();\n",
      "  Tensor* output_n = Tensor();\n",
      "\n",
      "  int64_t height_col = (output_height + 2 * padilation_height -\n",
      "                        (dilation_height * (kernel_height - 1) + 1)) /\n",
      "          stride_height +\n",
      "      1;\n",
      "  int64_t width_col = (output_width + 2 * padilation_width -\n",
      "                       (dilation_width * (kernel_width - 1) + 1)) /\n",
      "          stride_width +\n",
      "      1;\n",
      "\n",
      "  for (int64_t elt = 0; elt < batch_size; elt++) {\n",
      "    input_n.select(input, 0, elt);\n",
      "    output_n.select(output, 0, elt);\n",
      "\n",
      "    col2im<scalar_t, accreal>(\n",
      "        at::cuda::getCurrentCUDAStream(),\n",
      "        input_n.data(),\n",
      "        n_output_plane,\n",
      "        output_height,\n",
      "        output_width,\n",
      "        height_col,\n",
      "        width_col,\n",
      "        kernel_height,\n",
      "        kernel_width,\n",
      "        padilation_height,\n",
      "        padilation_width,\n",
      "        stride_height,\n",
      "        stride_width,\n",
      "        dilation_height,\n",
      "        dilation_width,\n",
      "        output_n)\n",
      "        .data();\n",
      "  }\n",
      "\n",
      "  // TODO: remove it: THCTensor_(free)(input_n);\n",
      "  // TODO: remove it: THCTensor_(free)(output_n);\n",
      "\n",
      "  if (!batched_input) {\n",
      "    output.resize_({n_output_plane, output_height, output_width});\n",
      "  }\n",
      "  // TODO: remove it: THCTensor_(free)(input);\n",
      "}\n",
      "\n",
      "void Col2Im_backward_out_cuda(\n",
      "\n",
      "    Tensor* grad_output,\n",
      "    Tensor* grad_input,\n",
      "    int64_t kernel_height,\n",
      "    int64_t kernel_width,\n",
      "    int64_t dilation_height,\n",
      "    int64_t dilation_width,\n",
      "    int64_t padilation_height,\n",
      "    int64_t padilation_width,\n",
      "    int64_t stride_height,\n",
      "    int64_t stride_width) {\n",
      "  IntArrayRef kernel_size = IntArrayRef({kernel_height, kernel_width});\n",
      "  IntArrayRef dilation = IntArrayRef({dilation_height, dilation_width});\n",
      "  IntArrayRef padding = IntArrayRef({padilation_height, padilation_width});\n",
      "  IntArrayRef stride = IntArrayRef({stride_height, stride_width});\n",
      "  at::native::cuda::im2col_out_cuda(\n",
      "      grad_output, grad_input, kernel_size, dilation, padding, stride);\n",
      "}\n",
      "\n",
      "// #endif\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# refresh output files\n",
    "create_aten_cuda_files(\n",
    "    output_path, \n",
    "    thcunn_path,\n",
    "    at_cuda_path,\n",
    "    zip(thcunn_files, at_cuda_files)\n",
    ")\n",
    "\n",
    "at_cuda_files_path = [\n",
    "    os.path.join(output_path, fn) \n",
    "    for fn in at_cuda_files\n",
    "]\n",
    "\n",
    "extra_rules = [\n",
    "    ('#include <THCUNN/Im2Col.h>', '#include <ATen/cuda/Im2Col.h>'),\n",
    "    ('kH', 'kernel_height'),\n",
    "    ('kW', 'kernel_width'),\n",
    "    ('dH', 'dilation_height'),\n",
    "    ('dW', 'dilation_width'),\n",
    "    ('padH', 'pad_height'),\n",
    "    ('padW', 'pad_width'),\n",
    "    ('sH', 'stride_height'),\n",
    "    ('sW', 'stride_width'),\n",
    "    ('nBlocksH', 'n_blocks_height'),\n",
    "    ('nBlocksW', 'n_blocks_width'),\n",
    "    ('shapeCheck', 'shape_check')\n",
    "]\n",
    "cuda_th2at(at_cuda_files_path, extra_rules)\n",
    "for fn in at_cuda_files:\n",
    "    !clang-format -i {output_path}/{fn}\n",
    "!cat {output_path}/{at_cuda_files[0]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
