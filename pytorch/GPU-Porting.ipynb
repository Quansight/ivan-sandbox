{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Porting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing functions:\n",
    " \n",
    "* THCUNN_check_dim_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/home/xmn/dev/quansight/tmp/pytorch/output'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "pytorch_path = '/home/xmn/dev/quansight/pytorch-project/pytorch'\n",
    "thcunn_path = os.path.join(pytorch_path, 'aten/src/THCUNN')\n",
    "at_cuda_path = os.path.join(pytorch_path, 'aten/src/ATen/native/cuda')\n",
    "\n",
    "thcunn_files = [\n",
    "    'SpatialUpSamplingBicubic.cu',\n",
    "    'SpatialUpSamplingBilinear.cu',\n",
    "    'SpatialUpSamplingNearest.cu',\n",
    "    'TemporalUpSamplingLinear.cu',\n",
    "    'TemporalUpSamplingNearest.cu',\n",
    "    'VolumetricUpSamplingNearest.cu',\n",
    "    'VolumetricUpSamplingTrilinear.cu'\n",
    "]\n",
    "thcunn_h_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove `aten/src/THNN/generic/*.c` files that is being ported\n",
    "# Remove functions to be ported from:\n",
    "# `/aten/src/THCUNN/CMakeLists.txt`\n",
    "# `/aten/src/THCUNN/generic/THCUNN.h`\n",
    "# `/aten/src/THNN/init.cpp`\n",
    "# `/aten/src/ATen/nn.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UpSampleBicubic2d.cu',\n",
       " 'UpSampleBilinear2d.cu',\n",
       " 'UpSampleNearest2d.cu',\n",
       " 'UpSampleLinear1d.cu',\n",
       " 'UpSampleNearest1d.cu',\n",
       " 'UpSampleNearest3d.cu',\n",
       " 'UpSampleTrilinear3d.cu']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _remove_ext(v):\n",
    "    if '.' in v:\n",
    "        return v.split('.')[0]\n",
    "    return v\n",
    "\n",
    "def _get_ext(v):\n",
    "    if '.' in v:\n",
    "        return '.' + v.split('.')[-1]\n",
    "    return ''\n",
    "    \n",
    "RULES_NAME = [\n",
    "    lambda v, w='Temporal': (\n",
    "        _remove_ext(v).replace(w, '') + '1d' + _get_ext(v)\n",
    "        if v.startswith(w)\n",
    "        else v\n",
    "    ),\n",
    "    lambda v, w='Spatial': (\n",
    "        _remove_ext(v).replace(w, '') + '2d' + _get_ext(v)\n",
    "        if v.startswith(w)\n",
    "        else v\n",
    "    ),\n",
    "    lambda v, w='Volumetric': (\n",
    "        _remove_ext(v).replace(w, '') + '3d' + _get_ext(v)\n",
    "        if v.startswith(w)\n",
    "        else v\n",
    "    ),\n",
    "]\n",
    "\n",
    "RULES_NAME_EXTRA = RULES_NAME + [\n",
    "    lambda v: v.replace('Sampling', 'Sample')\n",
    "]\n",
    "\n",
    "RULES = [] + RULES_NAME_EXTRA\n",
    "\n",
    "\n",
    "def apply_rules(rules, text):\n",
    "    _fn = text\n",
    "    for r in rules:\n",
    "        _fn = r(_fn)\n",
    "    return _fn\n",
    "\n",
    "\n",
    "def convert_filenames(filenames, extra_rules: list = []):\n",
    "    rules = RULES + extra_rules\n",
    "    \n",
    "    result = []\n",
    "    for fn in filenames:\n",
    "        result.append(apply_rules(rules, fn))\n",
    "    return result\n",
    "\n",
    "\n",
    "# test\n",
    "at_cuda_files = convert_filenames(thcunn_files)\n",
    "at_cuda_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xmn/dev/quansight/tmp/pytorch/output\n",
      "total 92K\n",
      "drwxrwxr-x 2 xmn xmn 4,0K abr 17 21:05 .\n",
      "drwxrwxr-x 3 xmn xmn 4,0K abr 17 20:36 ..\n",
      "-rw-rw-r-- 1 xmn xmn  11K abr 18 15:46 UpSampleBicubic2d.cu\n",
      "-rw-rw-r-- 1 xmn xmn  11K abr 18 15:46 UpSampleBilinear2d.cu\n",
      "-rw-rw-r-- 1 xmn xmn 8,6K abr 18 15:46 UpSampleLinear1d.cu\n",
      "-rw-rw-r-- 1 xmn xmn 7,4K abr 18 15:46 UpSampleNearest1d.cu\n",
      "-rw-rw-r-- 1 xmn xmn 8,6K abr 18 15:46 UpSampleNearest2d.cu\n",
      "-rw-rw-r-- 1 xmn xmn 9,9K abr 18 15:46 UpSampleNearest3d.cu\n",
      "-rw-rw-r-- 1 xmn xmn  14K abr 18 15:46 UpSampleTrilinear3d.cu\n"
     ]
    }
   ],
   "source": [
    "def create_aten_cuda_files(\n",
    "    output_path: str,\n",
    "    thcunn_path: str,\n",
    "    at_cuda_path: str,\n",
    "    th_at_filenames: list,\n",
    "    just_gpu_porting: bool = True\n",
    "): \n",
    "    \"\"\"Porting code from `/aten/src/THCUNN/generic` and `/aten/src/THCUNN`\n",
    "    to `/aten/src/ATen/native/cuda/`\n",
    "    \n",
    "    \"\"\"\n",
    "    for th_fn, at_fn in th_at_filenames:\n",
    "        # get file data from THCUNN\n",
    "        path_src = os.path.join(thcunn_path, th_fn)\n",
    "        at_file_output_path = os.path.join(output_path, at_fn)\n",
    "        # copy also properties and metadata\n",
    "        shutil.copy2(path_src, at_file_output_path)\n",
    "        # write output file\n",
    "        with open(at_file_output_path, 'a') as f_dst:\n",
    "            # get file data from THCUNN/generic\n",
    "            f_dst.write('\\n')\n",
    "            path_src = os.path.join(thcunn_path, 'generic', th_fn) \n",
    "            with open(path_src, 'r') as f_src:\n",
    "                f_dst.write('\\n// THCUNN/generic\\n')\n",
    "                f_dst.write(f_src.read())\n",
    "            \n",
    "            # get file data from ATen/native/cuda\n",
    "            # expetec a initial gpu porting after a `just cpu porting`\n",
    "            if just_gpu_porting:\n",
    "                f_dst.write('\\n')\n",
    "                path_src = os.path.join(at_cuda_path, at_fn)\n",
    "                with open(path_src, 'r') as f_src:\n",
    "                    f_dst.write('\\n// ATen/native/cuda\\n')\n",
    "                    f_dst.write(f_src.read())\n",
    "\n",
    "# test\n",
    "create_aten_cuda_files(\n",
    "    output_path, \n",
    "    thcunn_path,\n",
    "    at_cuda_path,\n",
    "    zip(thcunn_files, at_cuda_files)\n",
    ")\n",
    "\n",
    "print(output_path)\n",
    "!ls -lah {output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_replace_rule(by, to):\n",
    "    return lambda v: v.replace(by, to)\n",
    "\n",
    "\n",
    "def th2at(text: str, extra_rules: list = []):\n",
    "    # replace rules\n",
    "    replace_pair = [\n",
    "        ('#include <THCUNN/THCUNN.h>', '#include <ATen/ATen.h>'),\n",
    "        ('getSize(', 'size('),\n",
    "        (' int ', ' int64_t '),\n",
    "        ('Acctype', 'accscalar_t'),\n",
    "        ('Dtype', 'scalar_t'),\n",
    "        ('ScalarConvert<scalar_t, accscalar_t>::to',\n",
    "         'static_cast<accscalar_t>'),\n",
    "        ('ScalarConvert<accscalar_t, scalar_t>::to',\n",
    "         'static_cast<scalar_t>'),\n",
    "        ('THCNumerics<scalar_t>::min()',\n",
    "         'at::numeric_lmits<scalar_t>::lowest()'),\n",
    "        ('THCUNN_argCheck', 'AT_CHECK'),\n",
    "        ('THCTensor ', 'Tensor '),\n",
    "        ('THCTensor*', 'Tensor*'),\n",
    "        ('putWidth', 'put_width'),\n",
    "        ('putHeight', 'put_height'),\n",
    "        ('gradOut', 'grad_out'),\n",
    "        ('gradIn', 'grad_in'),\n",
    "        ('nBatch', 'nbatch'),\n",
    "        ('nChannel', 'nchannel'),\n",
    "        ('THCState *state,', ''),\n",
    "        ('THCDeviceTensor', 'PackedTensorAccessor'),\n",
    "        ('state, ', ''),\n",
    "        ('THCState_getCurrentStream(state)', 'at::cuda::getCurrentCUDAStream()'),\n",
    "        ('THArgCheck(', 'AT_CHECK('),\n",
    "    ] + extra_rules\n",
    "    for by, to in replace_pair:\n",
    "        text = text.replace(by, to)\n",
    "        \n",
    "    # regex rules\n",
    "    # TODO:\n",
    "    # - THCCeilDiv\n",
    "    # - toDeviceTensor\n",
    "    # - ::ne\n",
    "    # - ::min\n",
    "    # - THCTensor_(zero)\n",
    "    rules = (\n",
    "        # rule, output pattern \n",
    "        ('THNN_\\((.*)\\)', None),\n",
    "        ('THCTensor_\\(size\\)\\(([^,]*),\\s*(.*)\\)', '{}.size({})'),\n",
    "        ('THCTensor_\\(resize([0-9]*)d\\)\\(([^,]*),\\s*\\n*(.*)\\)', '{1}.resize({{ {2} }})  # {0}d'),\n",
    "        ('THCTensor_(nDimensionLegacyNoScalars)(\\s*(.*))', '{}.ndimension()'),\n",
    "        ('[!](.*)->is_empty()', '{}.numel() != 0'),\n",
    "        ('(\\w)\\s*!=\\s*NULL', '{}.defined()')\n",
    "    )\n",
    "    \n",
    "    for rule, output_format in rules:\n",
    "        result = re.finditer(rule, text, re.MULTILINE)\n",
    "        for r in result:\n",
    "            _in = r.group(0)\n",
    "            if output_format is None:\n",
    "                _out = r.group(1)\n",
    "            else:\n",
    "                _out = output_format.format(*r.groups())\n",
    "            text = text.replace(_in, apply_rules(RULES_NAME_EXTRA, _out))\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def cuda_th2at(files_path: list, extra_rules: list = []):\n",
    "    for f_path in files_path:\n",
    "        with open(f_path, 'r') as f:\n",
    "            f_content = th2at(f.read(), extra_rules)\n",
    "        \n",
    "        with open(f_path, 'w') as f:\n",
    "            f.write(f_content)\n",
    "            \n",
    "\n",
    "# test\n",
    "# refresh output files\n",
    "create_aten_cuda_files(\n",
    "    output_path, \n",
    "    thcunn_path,\n",
    "    at_cuda_path,\n",
    "    zip(thcunn_files, at_cuda_files)\n",
    ")\n",
    "\n",
    "at_cuda_files_path = [\n",
    "    os.path.join(output_path, fn) \n",
    "    for fn in at_cuda_files\n",
    "]\n",
    "\n",
    "extra_rules = [\n",
    "    ('#include <THCUNN/upsampling.h>', '#include <ATen/cuda/UpSample.h>')\n",
    "]\n",
    "cuda_th2at(at_cuda_files_path, extra_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UpSampleBicubic2d.cu\n",
      "--------------------------------------------------------------------------------\n",
      "rule:  THNN_\\((.*)\\)\n",
      "replace:  THNN_(SpatialUpSamplingBicubic_shapeCheck)  by:  UpSamplingBicubic_shapeCheck2d\n",
      "replace:  THNN_(SpatialUpSamplingBicubic_updateOutput)  by:  UpSamplingBicubic_updateOutput2d\n",
      "replace:  THNN_(SpatialUpSamplingBicubic_shapeCheck)  by:  UpSamplingBicubic_shapeCheck2d\n",
      "replace:  THNN_(SpatialUpSamplingBicubic_updateGradInput)  by:  UpSamplingBicubic_updateGradInput2d\n",
      "replace:  THNN_(SpatialUpSamplingBicubic_shapeCheck)  by:  UpSamplingBicubic_shapeCheck2d\n",
      "--------------------------------------------------------------------------------\n",
      "rule:  THCTensor_\\(size\\)\\(([^,]*),\\s*(.*)\\)\n",
      "replace:  THCTensor_(size)(state, input, 0)  by:  state.size(input, 0)\n",
      "replace:  THCTensor_(size)(state, input, 1)  by:  state.size(input, 1)\n",
      "replace:  THCTensor_(size)(state, input, 2)  by:  state.size(input, 2)\n",
      "replace:  THCTensor_(size)(state, input, 3)  by:  state.size(input, 3)\n",
      "replace:  THCTensor_(size)(state, input, 0)  by:  state.size(input, 0)\n",
      "replace:  THCTensor_(size)(state, input, 1)  by:  state.size(input, 1)\n",
      "--------------------------------------------------------------------------------\n",
      "rule:  THCTensor_\\(resize([0-9]*)d\\)\\(([^,]*),\\s*\n",
      "*(.*)\\)\n",
      "replace:  THCTensor_(resize4d)(state, gradInput, nbatch, nchannels, inputHeight, inputWidth)  by:  state.resize({ gradInput, nbatch, nchannels, inputHeight, inputWidth })  # 4d\n",
      "--------------------------------------------------------------------------------\n",
      "rule:  THCTensor_(nDimensionLegacyNoScalars)(\\s*(.*))\n",
      "--------------------------------------------------------------------------------\n",
      "rule:  [!](.*)->is_empty()\n",
      "replace:  !input->is_empty  by:  input.numel() != 0\n",
      "--------------------------------------------------------------------------------\n",
      "rule:  (\\w)\\s*!=\\s*NULL\n",
      "replace:  t != NULL  by:  t.defined()\n",
      "replace:  t != NULL  by:  t.defined()\n"
     ]
    }
   ],
   "source": [
    "# experimental\n",
    "for fn in at_cuda_files:\n",
    "    print('=' * 80)\n",
    "    print(fn)\n",
    "    with open(os.path.join(output_path, fn), 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    _rules = [\n",
    "        ('THNN_\\((.*)\\)', None),\n",
    "        ('THCTensor_\\(size\\)\\(([^,]*),\\s*(.*)\\)', '{}.size({})'),\n",
    "        ('THCTensor_\\(resize([0-9]*)d\\)\\(([^,]*),\\s*\\n*(.*)\\)', '{1}.resize({{ {2} }})  # {0}d'),\n",
    "        ('THCTensor_(nDimensionLegacyNoScalars)(\\s*(.*))', '{}.ndimension()'),\n",
    "        ('[!](.*)->is_empty()', '{}.numel() != 0'),\n",
    "        ('(\\w)\\s*!=\\s*NULL', '{}.defined()')\n",
    "    ]\n",
    "\n",
    "    for rule, output_format in _rules:\n",
    "        print('-' * 80)\n",
    "        print('rule: ', rule )\n",
    "        result = re.finditer(rule, text, re.MULTILINE)\n",
    "\n",
    "        for r in result:\n",
    "            _in = r.group(0)\n",
    "\n",
    "            if output_format is None:\n",
    "                _out = r.group(1)\n",
    "            else:\n",
    "                _out = output_format.format(*r.groups())\n",
    "\n",
    "            print('replace: ', _in, ' by: ', apply_rules(RULES_NAME, _out))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <ATen/ATen.h>\n",
      "#include <THC/THCTensor.hpp>\n",
      "#include <THCUNN/common.h>\n",
      "#include <ATen/cuda/UpSample.h>\n",
      "#include <THC/PackedTensorAccessor.cuh>\n",
      "#include <THC/PackedTensorAccessorUtils.cuh>\n",
      "#include <THC/THCDeviceUtils.cuh>\n",
      "#include <TH/THHalf.h>\n",
      "#include <THCUNN/THCHalfAutoNumerics.cuh>\n",
      "#include <THC/THCAtomics.cuh>\n",
      "\n",
      "template<typename scalar_t, typename accscalar_t>\n",
      "#if defined(__HIP_PLATFORM_HCC__)\n",
      "__launch_bounds__(1024)\n",
      "#endif\n",
      "__global__ void bicubic_interp2d_kernel(\n",
      "  const int64_t num_elements,\n",
      "  const accscalar_t height_scale,\n",
      "  const accscalar_t width_scale,\n",
      "  const PackedTensorAccessor<scalar_t, 4> in_data,\n",
      "  PackedTensorAccessor<scalar_t, 4> out_data\n",
      ") {\n",
      "\n",
      "  int64_t index = threadIdx.x + blockIdx.x * blockDim.x;\n",
      "  const int64_t batchsize = in_data.size(0);\n",
      "  const int64_t channels = in_data.size(1);\n",
      "  const int64_t input_height = in_data.size(2);\n",
      "  const int64_t input_width = in_data.size(3);\n",
      "  const int64_t output_height = out_data.size(2);\n",
      "  const int64_t output_width = out_data.size(3);\n",
      "\n",
      "  if (index >= num_elements) {\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  // Special case: input and output are the same size, just copy\n",
      "  const int64_t output_x = index % output_width;\n",
      "  const int64_t output_y = index / output_width;\n",
      "  if (input_height == output_height && input_width == output_width) {\n",
      "    for (int n = 0; n < batchsize; n++){\n",
      "      for (int c = 0; c < channels; c++) {\n",
      "        const scalar_t val = in_data[n][c][output_y][output_x];\n",
      "        out_data[n][c][output_x][output_y] = val;\n",
      "      }\n",
      "    }\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  // Interpolation kernel\n",
      "  accscalar_t real_x = width_scale * output_x;\n",
      "  int64_t in_x = real_x;\n",
      "  accscalar_t t_x = real_x - in_x;\n",
      "\n",
      "  accscalar_t real_y = height_scale * output_y;\n",
      "  int64_t in_y = real_y;\n",
      "  accscalar_t t_y = real_y - in_y;\n",
      "\n",
      "  for (int n = 0; n < batchsize ; n++) {\n",
      "    for (int c = 0; c < channels; c++) {\n",
      "      accscalar_t coefficients[4];\n",
      "\n",
      "      for (int k = 0; k < 4; k++) {\n",
      "        coefficients[k] = cubic_interp1d(\n",
      "          upsampling_get_value_bounded<scalar_t>(\n",
      "            in_data, c, n, input_width, input_height, in_x - 1, in_y - 1 + k),\n",
      "          upsampling_get_value_bounded<scalar_t>(\n",
      "            in_data, c, n, input_width, input_height, in_x + 0, in_y - 1 + k),\n",
      "          upsampling_get_value_bounded<scalar_t>(\n",
      "            in_data, c, n, input_width, input_height, in_x + 1, in_y - 1 + k),\n",
      "          upsampling_get_value_bounded<scalar_t>(\n",
      "            in_data, c, n, input_width, input_height, in_x + 2, in_y - 1 + k),\n",
      "          t_x\n",
      "        );\n",
      "      }\n",
      "\n",
      "      out_data[n][c][output_y][output_x] = static_cast<scalar_t>(cubic_interp1d(\n",
      "        coefficients[0],\n",
      "        coefficients[1],\n",
      "        coefficients[2],\n",
      "        coefficients[3],\n",
      "        t_y\n",
      "      ));\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "// Backward (adjoint) operation 1 <- 2 (accumulates)\n",
      "template <typename scalar_t, typename accscalar_t>\n",
      "#if defined(__HIP_PLATFORM_HCC__)\n",
      "__launch_bounds__(1024)\n",
      "#endif\n",
      "__global__ void bicubic_interp2d_backward_kernel(\n",
      "  const int64_t num_elements,\n",
      "  const accscalar_t height_scale,\n",
      "  const accscalar_t width_scale,\n",
      "  const bool align_corners,\n",
      "  PackedTensorAccessor<scalar_t, 4> in_data,\n",
      "  const PackedTensorAccessor<scalar_t, 4> out_data\n",
      "){\n",
      "\n",
      "  int64_t index = threadIdx.x + blockIdx.x * blockDim.x;\n",
      "  const int64_t batchsize = in_data.size(0);\n",
      "  const int64_t channels = in_data.size(1);\n",
      "  const int64_t input_height = in_data.size(2);\n",
      "  const int64_t input_width = in_data.size(3);\n",
      "  const int64_t output_height = out_data.size(2);\n",
      "  const int64_t output_width = out_data.size(3);\n",
      "\n",
      "  if (index >= num_elements) {\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  const int64_t output_x = index % output_width;\n",
      "  const int64_t output_y = index / output_width;\n",
      "  // special case: output_xust copy\n",
      "  if (input_height == output_height && input_width == output_width) {\n",
      "    for (int n = 0; n < batchsize ; n++){\n",
      "      for (int c = 0; c < channels; ++c) {\n",
      "        const scalar_t val = out_data[n][c][output_y][output_x];\n",
      "        in_data[n][c][output_y][output_x] += val;\n",
      "      }\n",
      "    }\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  accscalar_t real_x = width_scale * output_x;\n",
      "  int64_t input_x = real_x;\n",
      "  accscalar_t t_x = real_x - input_x;\n",
      "\n",
      "  accscalar_t real_y = height_scale * output_y;\n",
      "  int64_t input_y = real_y;\n",
      "  accscalar_t t_y = real_y - input_y;\n",
      "\n",
      "  accscalar_t x_coeffs[4];\n",
      "  accscalar_t y_coeffs[4];\n",
      "\n",
      "  get_cubic_upsampling_coefficients(x_coeffs, t_x);\n",
      "  get_cubic_upsampling_coefficients(y_coeffs, t_y);\n",
      "\n",
      "  for (int n = 0; n < batchsize ; n++){\n",
      "    for (int c = 0; c < channels; ++c) {\n",
      "      scalar_t out_value = out_data[n][c][output_y][output_x];\n",
      "      for (int i = 0; i < 4; i++) {\n",
      "        for (int j = 0; j < 4; j++) {\n",
      "          upsampling_increment_value_bounded<scalar_t, accscalar_t>(\n",
      "            in_data,\n",
      "            c,\n",
      "            n,\n",
      "            input_width,\n",
      "            input_height,\n",
      "            input_x - 1 + j,\n",
      "            input_y - 1 + i,\n",
      "            out_value * y_coeffs[i] * x_coeffs[j]\n",
      "          );\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "#include <THCUNN/generic/SpatialUpSamplingBicubic.cu>\n",
      "#include <THC/THCGenerateFloatTypes.h>\n",
      "\n",
      "\n",
      "// THCUNN/generic\n",
      "#ifndef THC_GENERIC_FILE\n",
      "#define THC_GENERIC_FILE \"THCUNN/generic/SpatialUpSamplingBicubic.cu\"\n",
      "#else\n",
      "\n",
      "#include <ATen/cuda/UpSample.h>\n",
      "#include <ATen/cuda/CUDAContext.h>\n",
      "\n",
      "static inline void UpSampleBicubic_shapeCheck2d\n",
      "                        (\n",
      "                         Tensor *input, Tensor *grad_output,\n",
      "                         int64_t nbatch, int64_t nchannels,\n",
      "                         int64_t input_height, int64_t input_width,\n",
      "                         int64_t output_height, int64_t output_width) {\n",
      "  AT_CHECK(input_height > 0 && input_width > 0\n",
      "             && output_height > 0 && output_width > 0, 2,\n",
      "             \"input and output sizes should be greater than 0,\"\n",
      "             \" but got input (H: %d, W: %d) output (H: %d, W: %d)\",\n",
      "             input_height, input_width, output_height, output_width);\n",
      "  if (input.defined()) {\n",
      "     AT_CHECK(input.numel() != 0() && input->dim() == 4, 2, input,\n",
      "                     \"non-empty 4D input tensor expected but got: %s\");\n",
      "  }\n",
      "\n",
      "  if (grad_output.defined()) {\n",
      "    THCUNN_check_dim_size(grad_output, 4, 0, nbatch);\n",
      "    THCUNN_check_dim_size(grad_output, 4, 1, nchannels);\n",
      "    THCUNN_check_dim_size(grad_output, 4, 2, output_height);\n",
      "    THCUNN_check_dim_size(grad_output, 4, 3, output_width);\n",
      "  }\n",
      "}\n",
      "\n",
      "void UpSampleBicubic_updateOutput2d(\n",
      "           \n",
      "           Tensor *input,\n",
      "           Tensor *output,\n",
      "           int64_t output_height,\n",
      "           int64_t output_width,\n",
      "           bool align_corners)\n",
      "{\n",
      "  int64_t nbatch = input.size(0);\n",
      "  int64_t channels = input.size(1);\n",
      "  int64_t input_height = input.size(2);\n",
      "  int64_t input_width = input.size(3);\n",
      "  UpSampleBicubic_shapeCheck2d\n",
      "       (input, NULL,\n",
      "        nbatch, channels,\n",
      "        input_height, input_width,\n",
      "        output_height, output_width);\n",
      "\n",
      "  THCUNN_assertSameGPU(2, input, output);\n",
      "  output.resize({ input.size(0 })  # 4d,\n",
      "                       input.size(1),\n",
      "                       output_height, output_width);\n",
      "  THCTensor_(zero)(output);\n",
      "  PackedTensorAccessor<scalar_t, 4> idata = toDeviceTensor<scalar_t, 4>(input);\n",
      "  PackedTensorAccessor<scalar_t, 4> odata = toDeviceTensor<scalar_t, 4>(output);\n",
      "  THAssert(input_height > 0 && input_width > 0 && output_height > 0 && output_width > 0);\n",
      "\n",
      "  // Get scaling factors\n",
      "  const accreal rheight = linear_upsampling_compute_scale<accreal>(input_height, output_height, align_corners);\n",
      "  const accreal rwidth = linear_upsampling_compute_scale<accreal>(input_width, output_width, align_corners);\n",
      "\n",
      "  const int64_t num_output_elements = output_height * output_width;\n",
      "  const int64_t max_threads =\n",
      "    at::cuda::getCurrentDeviceProperties()->maxThreadsPerBlock;\n",
      "\n",
      "  // Launch kernel\n",
      "  cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n",
      "  bicubic_interp2d_kernel<scalar_t, accreal> <<<\n",
      "    THCCeilDiv(num_output_elements, max_threads),\n",
      "    max_threads,\n",
      "    0,\n",
      "    stream\n",
      "  >>>(num_output_elements, rheight, rwidth, idata, odata);\n",
      "  THCudaCheck(cudaGetLastError());\n",
      "}\n",
      "\n",
      "\n",
      "void UpSampleBicubic_updateGradInput2d(\n",
      "           \n",
      "           Tensor *grad_output,\n",
      "           Tensor *grad_input,\n",
      "           int64_t nbatch,\n",
      "           int64_t nchannels,\n",
      "           int64_t input_height,\n",
      "           int64_t input_width,\n",
      "           int64_t output_height,\n",
      "           int64_t output_width,\n",
      "           bool align_corners)\n",
      "{\n",
      "  UpSampleBicubic_shapeCheck2d\n",
      "       (NULL, grad_output,\n",
      "        nbatch, nchannels,\n",
      "        input_height, input_width,\n",
      "        output_height, output_width);\n",
      "  grad_output = THCTensor_(newContiguous)(grad_output);\n",
      "  THCUNN_assertSameGPU(2, grad_output, grad_input);\n",
      "  grad_input.resize({ nbatch, nchannels, input_height, input_width })  # 4d;\n",
      "  THCTensor_(zero)(grad_input);\n",
      "  PackedTensorAccessor<scalar_t, 4> in_data = toDeviceTensor<scalar_t, 4>(grad_input);\n",
      "  PackedTensorAccessor<scalar_t, 4> out_data = toDeviceTensor<scalar_t, 4>(grad_output);\n",
      "  const accreal rheight = linear_upsampling_compute_scale<accreal>(input_height, output_height, align_corners);\n",
      "  const accreal rwidth = linear_upsampling_compute_scale<accreal>(input_width, output_width, align_corners);\n",
      "  const int64_t num_kernels = output_height * output_width;\n",
      "  const int64_t num_threads =\n",
      "    at::cuda::getCurrentDeviceProperties()->maxThreadsPerBlock;\n",
      "  cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n",
      "  bicubic_interp2d_backward_kernel<scalar_t ,accreal> <<<THCCeilDiv(num_kernels, num_threads),\n",
      "  num_threads, 0, stream>>>(num_kernels, rheight, rwidth, align_corners, in_data, out_data);\n",
      "  THCudaCheck(cudaGetLastError());\n",
      "  THCTensor_(free)(grad_output);\n",
      "}\n",
      "\n",
      "#endif\n",
      "\n",
      "\n",
      "// ATen/native/cuda\n",
      "#include <ATen/ATen.h>\n",
      "#include <ATen/NativeFunctions.h>\n",
      "#include <ATen/LegacyTHFunctions.h>\n",
      "\n",
      "namespace at {\n",
      "namespace native {\n",
      "\n",
      "Tensor& upsample_bicubic2d_out_cuda(\n",
      "    Tensor& output,\n",
      "    const Tensor& input,\n",
      "    IntArrayRef output_size,\n",
      "    bool align_corners) {\n",
      "    return at::legacy::th::_thnn_upsample_bicubic2d_forward_out(\n",
      "        output, input, output_size, align_corners);\n",
      "}\n",
      "\n",
      "Tensor upsample_bicubic2d_cuda(\n",
      "    const Tensor& input,\n",
      "    IntArrayRef output_size,\n",
      "    bool align_corners) {\n",
      "    return at::legacy::th::_thnn_upsample_bicubic2d_forward(\n",
      "        input, output_size, align_corners);\n",
      "}\n",
      "\n",
      "Tensor& upsample_bicubic2d_backward_out_cuda(\n",
      "    Tensor& grad_input,\n",
      "    const Tensor& grad_output,\n",
      "    IntArrayRef output_size,\n",
      "    IntArrayRef input_size,\n",
      "    bool align_corners) {\n",
      "    return at::legacy::th::_thnn_upsample_bicubic2d_backward_out(\n",
      "        grad_input, grad_output, output_size, input_size, align_corners);\n",
      "}\n",
      "\n",
      "Tensor upsample_bicubic2d_backward_cuda(\n",
      "    const Tensor& grad_output,\n",
      "    IntArrayRef output_size,\n",
      "    IntArrayRef input_size,\n",
      "    bool align_corners) {\n",
      "    return at::legacy::th::_thnn_upsample_bicubic2d_backward(\n",
      "        grad_output, output_size, input_size, align_corners);\n",
      "}\n",
      "\n",
      "} // native\n",
      "} // at\n"
     ]
    }
   ],
   "source": [
    "!cat {output_path}/{at_cuda_files[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually check:\n",
    "\n",
    "* `AT_CHECK` just have 2 args: condition and message\n",
    "* Check order of height, width in parameters of functions such as: resize,  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
